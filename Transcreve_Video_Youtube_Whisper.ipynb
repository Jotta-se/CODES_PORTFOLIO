{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMdOMNooUGogk82xISAzwyp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jotta-se/CODES_PORTFOLIO/blob/main/Transcreve_Video_Youtube_Whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baixa vídeo do Youtube e faz a transcrição usando Whisper\n",
        "by Jotta-se"
      ],
      "metadata": {
        "id": "Pmc9dyeTUhMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instruções\n",
        "1. Salve sua cópia desse Notebook no seu Colab\n",
        "2. Use GPU (T4)\n",
        "3. Rode as células individualmente.\n",
        "4. Atenção com espaços e caracteres especiais no nome do arquivo de vídeo/áudio (se preferir, renomeie-o)."
      ],
      "metadata": {
        "id": "UgtiSH5-UGVv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szVCLQZYMegg",
        "outputId": "4d93f5ba-a531-42ee-cf5d-8be78df46768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.3-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.3\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "# ATENÇÃO: (rode esta célula somente antes da primeira transcrição)\n",
        "\n",
        "!pip install pydub\n",
        "!pip install pytube\n",
        "!pip install SpeechRecognition\n",
        "!pip install moviepy\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configura acesso ao Google Drive\n",
        "(verifique se há espaço suficiente)"
      ],
      "metadata": {
        "id": "uHOtEWCEWHKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlrtUgx9Nchd",
        "outputId": "46407d23-e163-40ba-8bb9-867035d33630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defina a seguir os seguintes parâmetros\n",
        "### - URL do Vídeo no Youtube\n",
        "### - Linguagem Original do Vídeo (a tradução será realizada em passo posterior)\n",
        "### - Diretório de Download"
      ],
      "metadata": {
        "id": "tS0grzKWRKN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL do vídeo do YouTube\n",
        "video_url = \"https://youtu.be/GA2m-1m4zxk?si=38QKdvO1p7fJ4iXq\"\n",
        "\n",
        "# Linguagem do vídeo no Youtube\n",
        "linguagem = \"pt\"\n",
        "\n",
        "# Diretório de download\n",
        "download_dir = r\"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "EoBMU6uaNLu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baixa o Vídeo do Youtube"
      ],
      "metadata": {
        "id": "fpj9WqFLQk46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "\n",
        "# Baixar o vídeo\n",
        "def download_video(url, output_path):\n",
        "    # Criação de um objeto YouTube\n",
        "    yt = YouTube(url)\n",
        "    # Selecionar o stream de maior resolução disponível\n",
        "    stream = yt.streams.get_highest_resolution()\n",
        "    # Baixar o vídeo para um diretório local, retorna o caminho do arquivo baixado\n",
        "    return stream.download(output_path)\n",
        "\n",
        "# Caminho do arquivo baixado\n",
        "downloaded_video_path = download_video(video_url, download_dir)\n",
        "print(\"Vídeo baixado:\", downloaded_video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2ksFztMN5nc",
        "outputId": "7e50d4e4-d7b9-491e-f82a-b8f31d17f224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vídeo baixado: /content/drive/MyDrive/ENGENHARIA de PROMPTS com o CHAT GPT - Link da Descrição.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extrair o aúdio do vídeo no formato .wav"
      ],
      "metadata": {
        "id": "23h9zAdWQWuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# Função para extrair áudio do vídeo\n",
        "def extract_audio(video_path, output_format='wav'):\n",
        "    # Carregar o vídeo usando MoviePy\n",
        "    video_clip = VideoFileClip(video_path)\n",
        "    # Definir o caminho do arquivo de áudio de saída\n",
        "    audio_path = video_path.split('.')[0] + '.' + output_format\n",
        "    # Tirar os espaços do nome do vídeo\n",
        "    audio_path = audio_path.replace(' ', '')\n",
        "    # Extrair o áudio e salvar no formato especificado\n",
        "    video_clip.audio.write_audiofile(audio_path)\n",
        "    # Fechar o clip para liberar recursos\n",
        "    video_clip.close()\n",
        "    # Retornar o caminho do arquivo de áudio\n",
        "    return audio_path\n",
        "\n",
        "# Extrair o áudio do vídeo baixado\n",
        "audio_path = extract_audio(downloaded_video_path)\n",
        "audio_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "HELknBsQOrWs",
        "outputId": "0f93bcb6-e2c8-4339-dbcc-f956cb20e615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in /content/drive/MyDrive/ENGENHARIAdePROMPTScomoCHATGPT-LinkdaDescrição.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                       "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/ENGENHARIAdePROMPTScomoCHATGPT-LinkdaDescrição.wav'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transcrever o Áudio do Vídeo usando o Whisper\n",
        "\n",
        "(o arquivo de texto será salvo no seu Google Drive)"
      ],
      "metadata": {
        "id": "ugId_YBCP-YH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comando para realizar a transcrição\n",
        "!whisper {audio_path} --model medium --task transcribe --language {linguagem} --output_format txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XceFdNh3PiE3",
        "outputId": "70a1b18e-6864-4516-a0f5-19df6a603a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████████████████████████████████| 1.42G/1.42G [00:12<00:00, 119MiB/s]\n",
            "[00:00.000 --> 00:05.320]  Olá, tudo bem? Olha só, hoje eu vou começar uma série aqui no canal que faz tempo que eu tava\n",
            "[00:05.320 --> 00:09.960]  querendo fazer, mas como tem muita gente falando sobre o tema eu tava meio receoso de fazer pra não\n",
            "[00:09.960 --> 00:17.000]  ser repetitivo, mas eu acho que nesse caso vai ser interessante porque é uma série que você pode\n",
            "[00:17.000 --> 00:25.000]  usar tanto no desenvolvimento dos seus sistemas, usando o chat GPT ou GPT-4 ou GPT-3, como também\n",
            "[00:26.000 --> 00:32.800]  quando você vai usar o chat GPT no seu dia a dia, certo? Então eu vou mostrar pra vocês algumas\n",
            "[00:32.800 --> 00:37.880]  técnicas, algumas técnicas que são aplicadas e foram ensinadas pelo próprio pessoal da OpenAI.\n",
            "[00:37.880 --> 00:42.960]  Eu tô fazendo um curso com eles lá de como criar prompt efetivos, digamos assim, certo? E aí eu vou\n",
            "[00:42.960 --> 00:48.200]  dar algumas dicas, alguns vídeos serão algumas dicas sobre como fazer prompt efetivos dentro,\n",
            "[00:48.200 --> 00:52.840]  pra começar com o modelo do GPT-4, né? Então é o seguinte, vamos lá, vamos começar então.\n",
            "[00:53.000 --> 00:58.600]  Primeira dica que eu vou falar aqui com vocês é sobre delimitadores. Bom, eu vou primeiro mostrar\n",
            "[00:58.600 --> 01:02.400]  o exemplo, depois eu vou explicar porque os delimitadores funcionam tão bem, certo? Eu vou\n",
            "[01:02.400 --> 01:06.520]  fazer o seguinte, eu vou aqui escrever um texto, eu tenho um textozinho aqui que eu vou colocar pra\n",
            "[01:06.520 --> 01:10.360]  vocês, ó, vou colocar pra vocês esse texto e vou ler o texto porque acho que ele é importante, ó.\n",
            "[01:10.360 --> 01:15.200]  Você deve expressar o que deseja que o modelo faça, certo? Porém, são instruções que são tão claras\n",
            "[01:15.200 --> 01:21.040]  e tão específicas quanto possível. Isso guiará o modelo em uma direção saída desejada, certo? E\n",
            "[01:21.040 --> 01:25.640]  isso reduz as chances de receber mensagens irrelevantes ou respostas incorretas. Não\n",
            "[01:25.640 --> 01:31.480]  confunda escrever um prompt claro ao escrever um prompt curto, isso é interessante. Em muitos casos,\n",
            "[01:31.480 --> 01:37.280]  os promptes mais longos fornecem mais clareza e contexto para o modelo, o que pode levar a\n",
            "[01:37.280 --> 01:41.440]  resultados mais detalhados e relevantes. Bom, eu falei aqui que a gente vai falar sobre delimitadores,\n",
            "[01:41.440 --> 01:46.840]  né? Quando a gente tá mandando informação pro chat GPT, a gente tá mandando a informação toda\n",
            "[01:47.840 --> 01:53.080]  lá no modelo como se fosse uma variável, tá? Então, esse texto aqui, eu quero fazer um resumo\n",
            "[01:53.080 --> 01:56.560]  desse texto. Então, eu vou fazer o seguinte, ó, vou vir aqui em cima, eu quero que ele faça um resumo\n",
            "[01:56.560 --> 02:04.120]  desse texto pra mim, né? É, vamos ver aqui, eu tinha até criado já o texto do resumo. Então, faça um resumo,\n",
            "[02:05.120 --> 02:20.080]  faça um resumo do texto abaixo, certo? Em uma única, única frase, beleza? Quando você passa do\n",
            "[02:20.080 --> 02:28.640]  texto abaixo, ele, essa informação quando chega lá no chat GPT, esse abaixo ele é meio assim,\n",
            "[02:28.640 --> 02:34.000]  estranho, né? Porque você, ele vai achar tudo como se fosse uma string só, certo? Esses espaços\n",
            "[02:34.000 --> 02:39.400]  ele vai assumir, tá? Então, não é interessante você usar esse, essa estrutura, né? Faça um resumo\n",
            "[02:39.400 --> 02:45.720]  do texto abaixo, tá? Esse abaixo não é legal. O ideal mesmo é você criar uma delimitação para\n",
            "[02:45.720 --> 02:52.120]  o seu texto que você quer resumir, tá? E indicar na ação aonde está o texto, né, pela delimitação.\n",
            "[02:52.120 --> 02:58.560]  O que eu vou fazer aqui é o seguinte, ó, eu vou colocar aqui três acentos de crase, como se fosse\n",
            "[02:58.560 --> 03:03.080]  acento agudo, certo? Eu vou colocar aqui, ó, no início, vou copiar, vou lá pro fim e vou colar\n",
            "[03:03.080 --> 03:08.040]  três acentos de crase aqui. Então, agora, eu vou fazer o seguinte, ó, vou ter essa, essa, essa\n",
            "[03:08.040 --> 03:21.280]  informação aqui. Faça o resumo do texto delimitado por três backticks, né? Backticks, certo? Que são\n",
            "[03:21.280 --> 03:25.280]  em inglês, assim, três acentos agudos. Ou você pode colocar aqui, por três acentos crase, né?\n",
            "[03:26.800 --> 03:32.640]  Em uma única frase e você coloca ponto final aqui. Agora sim, o que acontece? Você imagina que\n",
            "[03:32.680 --> 03:37.000]  você vai dar lá essa informação na variável, é como se você estivesse criando uma variável dentro\n",
            "[03:37.000 --> 03:41.080]  da variável, certo? Quando você indica pra ele que ele tá sendo limitado, né, o texto tá sendo\n",
            "[03:41.080 --> 03:47.040]  delimitado por esses backticks, certo? Ele vai procurar no texto aonde estão, onde está o texto\n",
            "[03:47.040 --> 03:52.480]  que está limitado por backticks, certo? Então, aí, acontece. Ele pega, separa, né, isso aqui,\n",
            "[03:52.480 --> 03:57.840]  que é a ação pra uma variável, e ele separa esse texto aqui pra outra variável, entende? E aí ele\n",
            "[03:57.840 --> 04:01.560]  faz o processamento. É o que o pessoal da OpenAI recomenda, certo? É o que eles falaram que isso\n",
            "[04:01.880 --> 04:08.520]  é. Então vamos executar aqui e pedir que ele vai fazer aqui, ah, o resumo, ó. Então ele fala aí, ó.\n",
            "[04:10.760 --> 04:15.520]  Fez o resumozinho dele, né? E agora eu vou fazer o seguinte, por que pra ele esses backticks são tão\n",
            "[04:15.520 --> 04:20.440]  importantes? Então, vamos lá, vamos escrever esse aqui, ó. Escrever aqui pra ele aqui, ó. Por que\n",
            "[04:20.440 --> 04:25.200]  delimitar a frase entre os backticks é importante para o seu processamento? Vamos lá, vamos ver o que ele diz aqui, ó.\n",
            "[04:25.200 --> 04:34.280]  Aqui, ó. Ele fala aqui, ó. Bom, ele fala aqui, ó. Delimitar o texto com triplos backticks não é\n",
            "[04:34.280 --> 04:38.520]  importante para o processamento do texto em si, mas é uma convenção comum usada em linguagem de\n",
            "[04:38.520 --> 04:46.400]  marcação e programação, como Markdown ou GitHub, né, para indicar que o texto entre eles deve ser\n",
            "[04:46.400 --> 04:51.120]  tratado como um bloco de código ou uma citação. No entanto, no caso da sua pergunta, os backticks\n",
            "[04:51.120 --> 04:55.840]  foram usados para chamar minha atenção, ó. Foram usados para chamar minha atenção para o texto\n",
            "[04:55.840 --> 05:00.960]  específico que deve ser resumido. Legal, né? Então, assim, você perceba que ele mesmo diz o quanto é\n",
            "[05:00.960 --> 05:06.120]  importante. Sabe o que acontece? Eu sempre usava como delimitador aspas duplas ou aspas simples no\n",
            "[05:06.120 --> 05:11.400]  texto, né? E a recomendação é que você não faça isso, por quê? Porque no próprio texto você\n",
            "[05:11.400 --> 05:19.160]  passar pode ter algumas aspas duplas ou aspas simples que pode confundir, né, o próprio GPT, tá? Então a\n",
            "[05:19.160 --> 05:24.080]  recomendação da OpenAI é que não use aspas duplas, aspas simples para poder delimitar o texto\n",
            "[05:24.080 --> 05:28.200]  exatamente por isso, né, que você pode ter aspas duplas e simples dentro do texto. Só que o detalhe,\n",
            "[05:28.200 --> 05:33.240]  você não precisa usar somente backticks, tá? Você pode usar, segundo eles lá na OpenAI, você pode\n",
            "[05:33.240 --> 05:41.720]  usar triplo dashs, né, três sinais de menos, por exemplo. Você pode usar também o sinal de maior e\n",
            "[05:41.720 --> 05:48.360]  menor, só que o texto estaria aqui no meio, né? O texto estaria aqui no meio, certo? Você pode usar\n",
            "[05:48.360 --> 05:56.000]  também tags xml, por exemplo, você pode colocar aqui, ó, texto barra texto. E aí quando você for\n",
            "[05:56.000 --> 06:01.320]  delimitar, você diz que está entre as tags texto barra texto, entendeu? Então o texto estaria aqui\n",
            "[06:01.320 --> 06:06.200]  dentro, ó, o texto estaria aqui dentro, beleza? Legal, né, essa dica? Bom, agora eu vou fazer uma coisa prática, prática\n",
            "[06:06.200 --> 06:12.200]  mesmo. Olha o que eu vou fazer. Eu quero que, eu quero que ele crie pra mim o texto desse vídeo, tá\n",
            "[06:12.200 --> 06:16.920]  certo? Então eu vou fazer o seguinte, eu vou fazer assim, ó, vou colocar aqui, ó, baseado no texto delimitado\n",
            "[06:16.920 --> 06:22.200]  tags explicação barra explicação, cria um título que chame a atenção para o vídeo de YouTube. Aí\n",
            "[06:22.200 --> 06:26.840]  eu vou fazer o seguinte, eu vou vir aqui e vou colocar essas tags aqui, né, explicação barra explicação. Eu\n",
            "[06:26.840 --> 06:32.480]  gosto muito desse modelo de tags, né? Acho bacana. E aí agora eu vou colocar o texto explicando o que eu\n",
            "[06:32.480 --> 06:36.520]  quero que ele faça, né? Então vamos colocar aqui, ó, o texto que eu criei foi, estou criando uma série\n",
            "[06:36.520 --> 06:41.160]  sobre como construir promptos efetivos para o chat GPT recomendados pela OpenAI. O primeiro vídeo da\n",
            "[06:41.160 --> 06:46.640]  série é sobre usar delimitadores e textos prompt e como esses delimitadores ajudam na compreensão da\n",
            "[06:46.640 --> 06:51.280]  série do modelo. Vou mandar aqui o que ele colocar agora de título, é o que vai ser o título desse\n",
            "[06:51.280 --> 06:56.280]  vídeo, beleza? Vamos lá então. O título vai ser domínio chat GPT, descubra o poder dos delimitadores\n",
            "[06:56.280 --> 07:01.800]  no texto do primeiro episódio da série. Ficou um pouquinho grande, né? Aí eu vou fazer assim, ó, pode\n",
            "[07:01.800 --> 07:15.760]  criar um título, título menor. Vamos lá. Domínio chat GPT, o poder dos delimitadores. Ficou legal.\n",
            "[07:15.760 --> 07:20.880]  Acho que eu vou usar esse, tá? Domínio chat GPT, o poder dos delimitadores. Vamos lá, vai ser esse título\n",
            "[07:20.880 --> 07:26.120]  aqui, tá bom? Fica ligado porque eu vou fazer mais dicas aqui no canal Sandec sobre como você pode\n",
            "[07:26.120 --> 07:31.120]  usar melhor, construir melhor prompt para o chat GPT, valeu? Um grande abraço para você e até a próxima.\n"
          ]
        }
      ]
    }
  ]
}